{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from skimage.transform import resize\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, InputLayer"
      ],
      "metadata": {
        "id": "wp0arj8rEEqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "videoFile = \"tomnjerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"test%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkZRaZW-FX-D",
        "outputId": "a5551190-4088-4267-89d6-57c1929e198f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2idOHU0rkjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PboWHvk1Dhxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0787ec-7c1e-45c9-d731-c68f041839bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames captured.\n",
            "2/2 [==============================] - 13s 1s/step\n",
            "2/2 [==============================] - 13s 1s/step\n",
            "Epoch 1/12\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 1.7098 - accuracy: 0.3143\n",
            "Epoch 2/12\n",
            "2/2 [==============================] - 0s 193ms/step - loss: 1.5221 - accuracy: 0.6857\n",
            "Epoch 3/12\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 0.4626 - accuracy: 0.8286\n",
            "Epoch 4/12\n",
            "2/2 [==============================] - 0s 195ms/step - loss: 0.2165 - accuracy: 0.9143\n",
            "Epoch 5/12\n",
            "2/2 [==============================] - 0s 203ms/step - loss: 0.1761 - accuracy: 0.9143\n",
            "Epoch 6/12\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 0.1558 - accuracy: 0.8857\n",
            "Epoch 7/12\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 0.1371 - accuracy: 0.9143\n",
            "Epoch 8/12\n",
            "2/2 [==============================] - 0s 201ms/step - loss: 0.1287 - accuracy: 0.9429\n",
            "Epoch 9/12\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 0.1122 - accuracy: 0.9714\n",
            "Epoch 10/12\n",
            "2/2 [==============================] - 0s 199ms/step - loss: 0.0959 - accuracy: 0.9429\n",
            "Epoch 11/12\n",
            "2/2 [==============================] - 0s 204ms/step - loss: 0.0955 - accuracy: 0.9714\n",
            "Epoch 12/12\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 0.0973 - accuracy: 0.9714\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "The screen time of JERRY is 9.258399 seconds\n",
            "The screen time of TOM is 11.128458 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def capture_frames(video_file, output_prefix):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frameRate = cap.get(5)  # Frame rate\n",
        "    count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        frameId = cap.get(1)  # Current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frameId % math.floor(frameRate) == 0:\n",
        "            filename = f\"{output_prefix}{count}.jpg\"\n",
        "            cv2.imwrite(filename, frame)\n",
        "            count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Load an image and display it\n",
        "def load_and_display_image(image_path):\n",
        "    img = plt.imread(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "# Load and preprocess the images\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = plt.imread(img_path)\n",
        "        img = resize(img, preserve_range=True, output_shape=(224, 224)).astype(int)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Main function\n",
        "\n",
        "video_file = \"tomnjerry.mp4\"\n",
        "output_prefix = \"frame\"\n",
        "mapping_csv = \"mapping_29.csv\"\n",
        "testing_csv = \"testing_29.csv\"\n",
        "\n",
        "# Step 1: Capture frames from the video\n",
        "capture_frames(video_file, output_prefix)\n",
        "print(\"Frames captured.\")\n",
        "\n",
        "# Step 2: Load and preprocess frames\n",
        "data = pd.read_csv(mapping_csv)\n",
        "X = load_and_preprocess_images(data.Image_id)\n",
        "y = data.Class\n",
        "dummy_y = to_categorical(y)\n",
        "\n",
        "# Step 3: Load and preprocess test frames\n",
        "test_data = pd.read_csv(testing_csv)\n",
        "test_images = load_and_preprocess_images(test_data.Image_id)\n",
        "\n",
        "# Step 4: Load VGG16 model as a feature extractor\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Extract features from frames using the VGG16 model\n",
        "X_features = base_model.predict(X)\n",
        "test_features = base_model.predict(test_images)\n",
        "\n",
        "# Reshape the extracted features\n",
        "X_features = X_features.reshape(X_features.shape[0], -1)\n",
        "test_features = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "# Step 5: Build and train a classification model\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(X_features.shape[1],)))\n",
        "model.add(Dense(units=1024, activation='sigmoid'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history=model.fit(X_features, dummy_y, epochs=12)\n",
        "\n",
        "# Step 6: Make predictions on test frames\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate screen time\n",
        "jerry_screen_time = predictions[:, 1].sum()  # Assuming class 1 corresponds to JERRY\n",
        "tom_screen_time = predictions[:, 2].sum()    # Assuming class 2 corresponds to TOM\n",
        "\n",
        "print(\"The screen time of JERRY is\", jerry_screen_time, \"seconds\")\n",
        "print(\"The screen time of TOM is\", tom_screen_time, \"seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnpQluOQtqbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from skimage.transform import resize\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "count = 0\n",
        "\n",
        "def capture_frames(video_file, output_prefix):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frameRate = cap.get(5)  # Frame rate\n",
        "    count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        frameId = cap.get(1)  # Current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frameId % math.floor(frameRate) == 0:\n",
        "            filename = f\"{output_prefix}{count}.jpg\"\n",
        "            cv2.imwrite(filename, frame)\n",
        "            count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Load and preprocess the images\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = plt.imread(img_path)\n",
        "        img = resize(img, preserve_range=True, output_shape=(224, 224)).astype(int)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Main function\n",
        "video_file = \"tomnjerry.mp4\"\n",
        "output_prefix = \"frame\"\n",
        "mapping_csv = \"mapping_29.csv\"\n",
        "testing_csv = \"testing_29.csv\"\n",
        "\n",
        "# Step 1: Capture frames from the video\n",
        "capture_frames(video_file, output_prefix)\n",
        "print(\"Frames captured.\")\n",
        "\n",
        "# Step 2: Load and preprocess frames\n",
        "data = pd.read_csv(mapping_csv)\n",
        "X = load_and_preprocess_images(data.Image_id)\n",
        "y = data.Class\n",
        "dummy_y = to_categorical(y)\n",
        "\n",
        "# Step 3: Load and preprocess test frames\n",
        "test_data = pd.read_csv(testing_csv)\n",
        "test_images = load_and_preprocess_images(test_data.Image_id)\n",
        "\n",
        "# Step 4: Build and train a CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(X, dummy_y, epochs=10)\n",
        "\n",
        "# Step 5: Make predictions on test frames\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Calculate screen time\n",
        "jerry_screen_time = predictions[:, 1].sum()  # Assuming class 1 corresponds to JERRY\n",
        "tom_screen_time = predictions[:, 2].sum()    # Assuming class 2 corresponds to TOM\n",
        "\n",
        "print(\"The screen time of JERRY is\", jerry_screen_time, \"seconds\")\n",
        "print(\"The screen time of TOM is\", tom_screen_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESnPsutwFmvJ",
        "outputId": "4ea84291-45c6-4e04-c8a6-9dd817cf50ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames captured.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 111, 111, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 54, 54, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 26, 26, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 86528)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                5537856   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5631299 (21.48 MB)\n",
            "Trainable params: 5631299 (21.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 3s 262ms/step - loss: 235.6139 - accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 2s 187ms/step - loss: 236.1217 - accuracy: 0.3429\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 2s 198ms/step - loss: 60.0308 - accuracy: 0.3429\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 2s 184ms/step - loss: 15.4639 - accuracy: 0.2857\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 2s 181ms/step - loss: 5.0141 - accuracy: 0.5429\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 2s 189ms/step - loss: 4.4132 - accuracy: 0.3429\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 2s 279ms/step - loss: 1.3987 - accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 2s 180ms/step - loss: 2.6540 - accuracy: 0.5143\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 2s 183ms/step - loss: 3.0151 - accuracy: 0.4857\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 2s 175ms/step - loss: 0.7663 - accuracy: 0.7714\n",
            "2/2 [==============================] - 1s 52ms/step\n",
            "The screen time of JERRY is 14.755224 seconds\n",
            "The screen time of TOM is 13.256454 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "count = 0\n",
        "\n",
        "video_file = \"tomnjerry.mp4\"\n",
        "output_prefix = \"frame\"\n",
        "mapping_csv = \"mapping_29.csv\"\n",
        "testing_csv = \"testing_29.csv\"\n",
        "\n",
        "def capture_frames(video_file, output_prefix):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frameRate = cap.get(5)  # Frame rate\n",
        "    count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        frameId = cap.get(1)  # Current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frameId % math.floor(frameRate) == 0:\n",
        "            filename = f\"{output_prefix}{count}.jpg\"\n",
        "            cv2.imwrite(filename, frame)\n",
        "            count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = plt.imread(img_path)\n",
        "        img = resize(img, preserve_range=True, output_shape=(224, 224)).astype(int)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Step 1: Capture frames from the video\n",
        "capture_frames(video_file, output_prefix)\n",
        "print(\"Frames captured.\")\n",
        "\n",
        "# Step 2: Load and preprocess frames\n",
        "data = pd.read_csv(mapping_csv)\n",
        "X = load_and_preprocess_images(data.Image_id)\n",
        "y = data.Class\n",
        "dummy_y = to_categorical(y)\n",
        "\n",
        "# Step 3: Load and preprocess test frames\n",
        "test_data = pd.read_csv(testing_csv)\n",
        "test_images = load_and_preprocess_images(test_data.Image_id)\n",
        "\n",
        "# Step 4: Load ResNet-50 model as a feature extractor\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Extract features from frames using the ResNet-50 model\n",
        "X_features = base_model.predict(preprocess_input(X))\n",
        "test_features = base_model.predict(preprocess_input(test_images))\n",
        "\n",
        "# Step 5: Build and train a classification model\n",
        "model = Sequential()\n",
        "model.add(GlobalAveragePooling2D(input_shape=X_features.shape[1:]))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_features, dummy_y, epochs=10)\n",
        "\n",
        "# Step 6: Make predictions on test frames\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate screen time\n",
        "jerry_screen_time = predictions[:, 1].sum()  # Assuming class 1 corresponds to JERRY\n",
        "tom_screen_time = predictions[:, 2].sum()    # Assuming class 2 corresponds to TOM\n",
        "\n",
        "print(\"The screen time of JERRY is\", jerry_screen_time, \"seconds\")\n",
        "print(\"The screen time of TOM is\", tom_screen_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYJFNSttu5fP",
        "outputId": "be10dd68-ec84-4897-9691-fc44cb0049e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames captured.\n",
            "2/2 [==============================] - 42s 302ms/step\n",
            "2/2 [==============================] - 4s 310ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.7404 - accuracy: 0.3143\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.4007 - accuracy: 0.5143\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4025 - accuracy: 0.8286\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4730 - accuracy: 0.5429\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5202 - accuracy: 0.6857\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3046 - accuracy: 0.8571\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2423 - accuracy: 0.9429\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1546 - accuracy: 0.9714\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1172 - accuracy: 0.9429\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0438 - accuracy: 0.9714\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "The screen time of JERRY is 10.180044 seconds\n",
            "The screen time of TOM is 11.949773 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "count = 0\n",
        "\n",
        "videoFile = \"tomnjerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5)  # frame rate\n",
        "x = 1\n",
        "while cap.isOpened():\n",
        "    frameId = cap.get(1)  # current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if frameId % math.floor(frameRate) == 0:\n",
        "        filename = \"test%d.jpg\" % count\n",
        "        count += 1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print(\"Done!\")\n",
        "\n",
        "def capture_frames(video_file, output_prefix):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frameRate = cap.get(5)  # Frame rate\n",
        "    count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        frameId = cap.get(1)  # Current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frameId % math.floor(frameRate) == 0:\n",
        "            filename = f\"{output_prefix}{count}.jpg\"\n",
        "            cv2.imwrite(filename, frame)\n",
        "            count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Load an image and display it\n",
        "def load_and_display_image(image_path):\n",
        "    img = plt.imread(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "# Load and preprocess the images\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = plt.imread(img_path)\n",
        "        img = resize(img, preserve_range=True, output_shape=(299, 299)).astype(int)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Main function\n",
        "video_file = \"tomnjerry.mp4\"\n",
        "output_prefix = \"frame\"\n",
        "mapping_csv = \"mapping_29.csv\"\n",
        "testing_csv = \"testing_29.csv\"\n",
        "\n",
        "# Step 1: Capture frames from the video\n",
        "capture_frames(video_file, output_prefix)\n",
        "print(\"Frames captured.\")\n",
        "\n",
        "# Step 2: Load and preprocess frames\n",
        "data = pd.read_csv(mapping_csv)\n",
        "X = load_and_preprocess_images(data.Image_id)\n",
        "y = data.Class\n",
        "dummy_y = to_categorical(y)\n",
        "\n",
        "# Step 3: Load and preprocess test frames\n",
        "test_data = pd.read_csv(testing_csv)\n",
        "test_images = load_and_preprocess_images(test_data.Image_id)\n",
        "\n",
        "# Step 4: Load InceptionV3 model as a feature extractor\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "# Extract features from frames using the InceptionV3 model\n",
        "X_features = base_model.predict(preprocess_input(X))\n",
        "test_features = base_model.predict(preprocess_input(test_images))\n",
        "\n",
        "# Step 5: Build and train a classification model\n",
        "model = Sequential()\n",
        "model.add(GlobalAveragePooling2D(input_shape=X_features.shape[1:]))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_features, dummy_y, epochs=10)\n",
        "\n",
        "# Step 6: Make predictions on test frames\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate screen time\n",
        "jerry_screen_time = predictions[:, 1]  # Assuming class 1 corresponds to JERRY\n",
        "tom_screen_time = predictions[:, 2]    # Assuming class 2 corresponds to TOM\n",
        "\n",
        "print(\"The screen time of JERRY is\", jerry_screen_time.sum(), \"seconds\")\n",
        "print(\"The screen time of TOM is\", tom_screen_time.sum(), \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOx3c6MLwER2",
        "outputId": "e92e53f1-9d4f-43c4-f062-f65e05d00d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "Frames captured.\n",
            "2/2 [==============================] - 6s 394ms/step\n",
            "2/2 [==============================] - 5s 574ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4013 - accuracy: 0.3429\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.9967 - accuracy: 0.3714\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.0454 - accuracy: 0.5429\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3826 - accuracy: 0.8286\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6323 - accuracy: 0.6571\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9466 - accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.8286\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3856 - accuracy: 0.8571\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2452 - accuracy: 0.9714\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1549 - accuracy: 0.9429\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "The screen time of JERRY is 13.872986 seconds\n",
            "The screen time of TOM is 12.099193 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications import DenseNet121\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "count = 0\n",
        "\n",
        "videoFile = \"tomnjerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5)  # frame rate\n",
        "x = 1\n",
        "while cap.isOpened():\n",
        "    frameId = cap.get(1)  # current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if frameId % math.floor(frameRate) == 0:\n",
        "        filename = \"test%d.jpg\" % count\n",
        "        count += 1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print(\"Done!\")\n",
        "\n",
        "def capture_frames(video_file, output_prefix):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frameRate = cap.get(5)  # Frame rate\n",
        "    count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        frameId = cap.get(1)  # Current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frameId % math.floor(frameRate) == 0:\n",
        "            filename = f\"{output_prefix}{count}.jpg\"\n",
        "            cv2.imwrite(filename, frame)\n",
        "            count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Load and preprocess the images\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = plt.imread(img_path)\n",
        "        img = resize(img, preserve_range=True, output_shape=(224, 224)).astype(int)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Main function\n",
        "video_file = \"tomnjerry.mp4\"\n",
        "output_prefix = \"frame\"\n",
        "mapping_csv = \"mapping_29.csv\"\n",
        "testing_csv = \"testing_29.csv\"\n",
        "\n",
        "# Step 1: Capture frames from the video\n",
        "capture_frames(video_file, output_prefix)\n",
        "print(\"Frames captured.\")\n",
        "\n",
        "# Step 2: Load and preprocess frames\n",
        "data = pd.read_csv(mapping_csv)\n",
        "X = load_and_preprocess_images(data.Image_id)\n",
        "y = data.Class\n",
        "dummy_y = to_categorical(y)\n",
        "\n",
        "# Step 3: Load and preprocess test frames\n",
        "test_data = pd.read_csv(testing_csv)\n",
        "test_images = load_and_preprocess_images(test_data.Image_id)\n",
        "\n",
        "# Step 4: Load DenseNet model as a feature extractor\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Extract features from frames using the DenseNet model\n",
        "X_features = base_model.predict(X)\n",
        "test_features = base_model.predict(test_images)\n",
        "\n",
        "# Step 5: Build and train a classification model\n",
        "model = Sequential()\n",
        "model.add(GlobalAveragePooling2D(input_shape=X_features.shape[1:]))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_features, dummy_y, epochs=10)\n",
        "\n",
        "# Step 6: Make predictions on test frames\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate screen time\n",
        "jerry_screen_time = predictions[:, 1]  # Assuming class 1 corresponds to JERRY\n",
        "tom_screen_time = predictions[:, 2]    # Assuming class 2 corresponds to TOM\n",
        "\n",
        "print(\"The screen time of JERRY is\", jerry_screen_time.sum(), \"seconds\")\n",
        "print(\"The screen time of TOM is\", tom_screen_time.sum(), \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69uQh7xWxsAZ",
        "outputId": "b5fe91d6-eb60-48a6-b5af-95a6860c79b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "Frames captured.\n",
            "2/2 [==============================] - 5s 253ms/step\n",
            "2/2 [==============================] - 3s 367ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.2843 - accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 26.1278 - accuracy: 0.4286\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.2875 - accuracy: 0.3714\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.1248 - accuracy: 0.6571\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.6008 - accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.6810 - accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6567 - accuracy: 0.8286\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0393 - accuracy: 0.7143\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1933 - accuracy: 0.8286\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7977 - accuracy: 0.8000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "The screen time of JERRY is 8.051988 seconds\n",
            "The screen time of TOM is 8.927066 seconds\n"
          ]
        }
      ]
    }
  ]
}